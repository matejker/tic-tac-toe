<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="main.css">
    <title>Tic-Tac-Toe</title>
</head>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
        type="text/javascript"></script>
<script src="./chart.js"></script>
<script src="game.js" type="text/javascript"></script>
<script src="minimax.js" type="text/javascript"></script>
<script src="menace.js" type="text/javascript"></script>
<script>
    const createAllGames = () => {
        createGame(1);
        makeTurn(cells, 1);
        initiateMenaceMemory();
        createGameMenace(2);
    }
</script>
<body onload="createAllGames()">
<div id="main">
    <h1>Tic-Tac-Toe</h1>
    <em class="description">
        or how to achieve an optimal strategy with game theory, reinforcement learning... and bunch of matchboxes
    </em>
    <h2>Chapters</h2>
    <ol>
        <li><a href="#what">What?!</a></li>
        <li><a href="#algebra">Board, groups, symmetries and ternary numbers</a></li>
        <li><a href="#minmax">Game theory and minimax theorem</a></li>
        <li><a href="#menace">MENACE or a pile of matchboxes mastering the game</a></li>
        <li><a href="#reinforcement-learning">Reinforcement learning</a></li>
    </ol>
    <h2 id="what">What?!</h2>
    <p>
        <em>Tic-tac-toe</em> or in british english <em>noughts and crosses</em> is an ancient game which
        <em>every</em> seven years old children learns how to play and not to lose in exactly nine plays or so. Why would
        you spend your time with playing and studying such a triviality? Well, I got interested in Reinforcement
        learning
        recently. So I can use it for
        <a href="https://github.com/matejker/controllability-of-complex-networks">some more nasty stuff</a> and
        <em>tic-tac-toe</em> is a classic example such that even Sutton & Barto [3] don't hesitate to put it
        into the book's introduction.
    </p>
    <p>
        As well as many other <em>trendy</em> machine learning techniques were invented in the early 60s [4], so does
        Reinforcement learning. I was <em>shocked</em> (ok, positively surprised) when I watched one of Hanna Fry's
        Christmas lectures where <a href="https://youtu.be/TtisQ9yZ2zo?t=2210">Matt Parker came
        with a pile of matchboxes</a> which could play <em>noughts and crosses</em>. For my surprise it wasn't Matt
        Parker who invented it, not even <em>in-that-time PhD student</em> Matt Scroggs [5] who he referred in his
        <a href="https://www.youtube.com/watch?v=R9c-_neaxeU">previous video</a>. It was a former Bletchley Park
        researcher <a href="https://en.wikipedia.org/wiki/Donald_Michie">Donald Michie</a> in 1960 who came up with a
        smart way how to teach a bunch of matchboxes with beads in it to play <em>noughts and crosses</em> [1, 2].
    </p>
    <p>
        However, <em>every seven years old children learns how to play and not to lose</em>, it is possible to find and
        check all possible games, and define perfect unbeatable player which won't lose any game. To do that, we will
        take a look at game theory approach. [6]
    </p>
    <p>
        In this <em>article</em>, I try to explain some valuable math properties about the game and try to
        come up with a few ways how to teach a computer to play <em>tic-tac-toe</em>.
    </p>

    <h2 id="algebra">Board, groups, symmetries and ternary numbers</h2>
    <p>
        The <em>tic-tac-toe</em> board is a 3 &times; 3 square-shaped grid. For simplicity and future references,
        let's denote all the fields by numbers 0-8, where the center position is 0. In each turn, new "O"
        <em>noughts</em>
        and "X" <em>crosses</em> are added and the board is filling up. Some of the board settings are
        <em>indentical</em>
        up-to-some transformation. As you can see on the picture bellow, both of the boards are <em>equal</em> - the
        second one is rotated 90&deg; to the left.
    </p>
    <div class="center"><img src="img/order.png"></div>
    <p>
        In abstract algebra, we call such operations under which the object is invariant a <strong>symmetry
        group</strong>.
        In the <em>tic-tac-toe</em> case, the underlying shape of the board is a square, therefore, we would be
        interested in symmetry group of square. Figure bellow shows that we can reflect the square grid about four axes:
        <em>t<sub>x</sub>, t<sub>y</sub>, t<sub>AC</sub></em> and <em>t<sub>BD</sub></em>, and rotate entire grid about
        90&deg; <em>r</em>, 180&deg; <em>r<sup>2</sup></em> and 270&deg; <em>r<sup>3</sup></em>, and still get the
        <em>same</em> square.
    </p>
    <div class="side-note">
        <p>
            This group is called <em>Dihedral Group D<sub>4</sub></em> and it has 8 elements. Generated by
            ‚ü®a,b:a<sup>4</sup>=b<sup>2</sup>=2,ab=ba‚àí1‚ü©
            For more details see <a href="https://proofwiki.org/wiki/Definition:Dihedral_Group_D4">ProofWiki</a>.
        </p>
    </div>
    <div class="center"><img src="img/symmetries.png"></div>
    <h3>Permutations</h3>
    <p>
        Each of those <em>group elements</em> {<em>e, r, r<sup>2</sup>, r<sup>3</sup>, t<sub>x</sub>, t<sub>y</sub>,
        t<sub>AC</sub>, t<sub>BD</sub></em>} has its own <em>permutation</em> or a mapping for each element projection.
        For example, an element <em>r</em> rotates the board about 90&deg; to the right, therefore, 0 field maps back to
        0, 1 goes to 7, 2->8, 3->1, 4->2, 5->3, 6->4, 7->5, 8->6. However, such notation is a bit confusing we can
        adopt widely used one - (0, 7, 8, 1, 2, 3, 4, 5, 6), where position or <em>index</em> is the <em>origin</em>
        and value is the <em>target</em>. In the following table, we can see all the elements' permutations.
    </p>
    <div class="side-note">
        <p>
            Worth noticing that <em>tic-tac-toe permutations</em> do not form the entire permutation group for 8-element
            set <em>S<sub>8</sub></em>. Some permutations would <em>deform</em> the square grid, e.g.
            applying (1, 2) on the board changes it such that 1 is no longer neighbour with 8, etc.
            For more details see
            <a href="https://proofwiki.org/wiki/Cycle_Notation/Examples/Permutations_in_S8">ProofWiki</a>.
        </p>
    </div>
    <div class="center">
        <table style="width: 500px; margin: 0 auto;">
            <tr>
                <th>element</th>
                <th>permutation</th>
                <th>short <em>cycle</em> form<sup><a href="#permutation-cycle-note">1)</a></sup></th>
            </tr>
            <tr>
                <td><em>e</em></td>
                <td>(0, 1, 2, 3, 4, 5, 6, 7, 8)</td>
                <td>()</td>
            </tr>
            <tr>
                <td><em>r</em></td>
                <td>(0, 7, 8, 1, 2, 3, 4, 5, 6)</td>
                <td>(7, 8, 1, 2, 3, 4, 5, 6)</td>
            </tr>
            <tr>
                <td><em>r<sup>2</sup></em></td>
                <td>(0, 5, 6, 7, 8, 1, 2, 3, 4)</td>
                <td>(5, 6, 7, 8, 1, 2, 3, 4)</td>
            </tr>
            <tr>
                <td><em>r<sup>3</sup></em></td>
                <td>(0, 3, 4, 5, 6, 7, 8, 1, 2)</td>
                <td>(3, 4, 5, 6, 7, 8, 1, 2)</td>
            </tr>
            <tr>
                <td><em>t<sub>x</sub></em></td>
                <td>(0, 7, 6, 5, 4, 3, 2, 1, 8)</td>
                <td>(1,7) (2, 6) (3, 5)</td>
            </tr>
            <tr>
                <td><em>t<sub>y</sub></em></td>
                <td>(0, 3, 2, 1, 8, 7, 6, 5, 4)</td>
                <td>(1,3) (4, 8) (5, 7)</td>
            </tr>
            <tr>
                <td><em>t<sub>AC</sub></em></td>
                <td>(0, 1, 8, 7, 6, 5, 4, 3, 2)</td>
                <td>(2, 8) (3, 7) (4, 6)</td>
            </tr>
            <tr>
                <td><em>t<sub>BD</sub></em></td>
                <td>(0, 5, 4, 3, 2, 1, 8, 7, 6)</td>
                <td>(1,5) (2, 4) (6, 8)</td>
            </tr>
        </table>
    </div>
    <p>
        As you can see the center field 0 remains fixed for all permutations, which is pretty obvious and gives a clue
        why we chose 0 as the origin and why the rest of numbers go clockwise all around...
    </p>

    <h3>Ternary numbers</h3>
    <div class="side-note">
        <p>
            If we were interested in the game evolution - how "O" and "X" were added in each turn, we could denote the
            game as series of fields, e.g. 032 corresponds to üëá
        <div class="center"><img src="img/032.png" style="width: 130px"></div>
        </p>
    </div>

    <p>
        Another handy piece in this <em>tic-tac-toe-algebra puzzle</em> are ternary numbers. All of us are
        familiar with decimal, hexadecimal and binary numbers, but numbers with base 3 are less common. For the game
        purposes they suits perfectly as they denote board fields with 0 for empty ones, 1 for "O" and 2 for "X". For
        example two boards mentioned before, their ternary numbers are 201000000 and 200010000 respectively.
    </p>

    <h3>Number of possible boards</h3>
    <p>
        Part of a reason why we did all the ‚òùÔ∏è algebra was to came up with number of possible <em>tic-tac-toe</em>
        boards. We know that the theoretical upper bound of possible games is <strong>9! = 362 880</strong>. Factorial
        takes in count also boards where the game already ended but we added another steps.
        <a href="http://www.se16.info/hgb/tictactoe.htm">Henry Bottomley's</a> came up with nice calculations where they
        estimated <strong>255 168</strong> possible games.
    </p>
    <p>
        We know that we can do even better by removing all the symmetrical boards, we can count the numbers using some
        more advance algebra e.g. <a href="https://en.wikipedia.org/wiki/Burnside%27s_lemma">Burnside's lemma</a>
        [without any further calculations] can give us better estimate of <strong>19 683</strong>
        <sup><a href="#counting-thm-note">2)</a></sup> or write a fairly
        <a href="https://github.com/matejker/tic-tac-toe/blob/main/tic_tac_toe/utils/permutations.py">short code</a>.
    </p>
    <script src="https://gist.github.com/matejker/454e43d7be6d815903fbcfb6b4834833.js"></script>
    <p>
        Which give us <strong>765</strong> possible achievable positions where only <strong>138</strong> are possible
        games regardless on the order of players' moves and transformations.
    </p>

    <p>
        Putting it all together, we saw that some boards are equivalent up to a symmetry, to find all symmetries for
        given board we can use the permutations obtained from the symmetry group of square. This observation
        saved us few thousands boards and we can concentrate on a few <em>classes</em> of boards. For easier notation,
        we can use handy ternary numbers to denote the boards.
    </p>

    <h2 id="minmax">Game theory and minimax theorem</h2>
    <p>
        <em>Tic-tac-toe</em> is a <a href="https://en.wikipedia.org/wiki/Complete_information">perfect information</a>
        <a href="https://en.wikipedia.org/wiki/Zero-sum_game">zero-sum game</a>, which means that both players know or
        at least can find result for all possible moves and when one wins second one lose, and <em>vice versa</em>.
        From ‚òùÔ∏è computations we know that there are only
        <strong>765</strong> possible achievable boards which is not that hard to check them all and find the optimal
        strategy - unbeatable player which can not lose only draw and win.
    </p>
    <div class="center">
        <table class="tic-tac-toe" id="tic-tac-toe-1">

        </table> <br>
        <button onclick="resetGame(1)">Start again</button>
        <span id="who-won-1"></span> <br>
        <span class="image-desc">
            Computer uses minimax algorithm and plays optimally. If more available options have the same score,
            it chooses one action at random.
        </span>
    </div>
    <p>
        Therefore, we would like to find moves which <em>maximize</em> chances of winning and <em>minimize</em>
        opponent's chances. In other words - we want to maximize reward and minimize harm in the game. Such an algorithm
        is called Minimax [6] based on fundamental <a href="https://en.wikipedia.org/wiki/Minimax_theorem">minimax
        theorem</a>.
    </p>

    <div class="center">
        <img src="img/neumann.jpeg" style="width: 95%">
        <span class="image-desc">
            John von Neumann who proved the Minimax theorem in 1928,
            which is considered the starting point of game theory.
        </span>
    </div>
    <h3>Minimax algorithm</h3>
    <p>
        In simulation, when computer player is on turn, it tries to choose actions which have the highest value.
        We assume that opponent is also a perfect and rational player trying to win and play optimally - the opponent
        is playing the best available action. Therefore, on opponent's turns we consider the action with the minimum
        value.
    </p>
    <div class="center">
        <img src="img/minimax.png" style="width: 95%">
        <span class="image-desc">Evolution of all possible boards from "020102112".</span>
    </div>
    <p>
        For every possible action of the board we check what is the value. If computer will win for that action, we assign
        value "10 - <em>distance between current board and the winning board</em>" or depth. On the other hand, if the
        action lead to losing the game, we use "depth - 10" as the value. For other scenarios we assign 0.
    </p>
    <p>
        The figure above shows all possible turns for "020102112" board and value for each path. However, it is "X" turn
        we are looking for maximum possible value which is "+9". Now we can clearly see that, if player "X" is not
        playing the "220102112" (middle board) and "O" is perfect player, then "O" tries to maximize its value and plays
        "12x1x2112". For further analysis check the code bellow.
    </p>

    <script src="https://gist.github.com/matejker/2f4f8b4fdd8b637eba714be5f9ee851b.js"></script>

    <h2 id="menace">MENACE or a pile of matchboxes mastering the game</h2>
    <p>
        In the times when fast computers were not around, but the concept of <em>computation</em> excited many scientists.
        British researcher Donald Michie invented <em>very</em> clever idea how to teach matchboxes with colorful beads
        to play <em>noughts and crosses</em>, which he named "<em>Matchbox Educable Noughts and Crosses Engine</em>"
        or <strong>MENACE</strong>.
    </p>
    <div class="center">
        <img src="img/beads.png" style="width: 65%">
        <span class="image-desc">Colors of each position, D. Michie [1]</span>
    </div>
    <p>
        Each position on the board has its own colour (see picture ‚òùÔ∏è). For every possible board there is a matchbox,
        bear in mind that we consider only unique symmetry classes. In the first turn matchbox there  are
        <em>initially</em> 4 beads of each possible action represented by the coloured of the beads. For the matchboxes
        representing third turn, there are 3 beads of each colour, for fifth turns' 2 and for seventh 1. A bead chosen
        at random decides what action to do
        at every turn. The opponent turn then define next matchbox and the process is repeated until of the player wins
        or it is a draw. If the chosen beads led to a winning the game, we add 3 of each color to a corresponding
        matchbox. If game is a draw, we add 1 extra bead for each matchbox. If MENACE lost the game, we remove the beads.
    </p>
    <div class="center">
        <img src="img/menace.png" style="width: 95%">
        <span class="image-desc">The matchbox machine MENACE build by D. Michie [1]</span>
    </div>
    <p>
        The fundamental idea of MENACE is to add beads which led to winning and drawing the game, and remove beads which
        lost the game. <em>Hopping</em> that as more it plays games, the more <em>unbeatable</em> it will be.
    </p>
    <div class="center">
        <table class="tic-tac-toe" id="tic-tac-toe-2">

        </table> <br>
        <button onclick="resetGameMenace(2)">Start again</button>
        <span id="who-won-2"></span> <br>
    </div>
    <h3>Change in number of beads in the first box</h3>
    <div class="center">
        <div style="width: 100%; height: 350px;"><canvas id="myChart" width="2" height="1"></canvas></div>
    </div>
    <h3>Menace's matchbox <em>brain</em></h3>
    <p>
        Each game below represents a matchbox with colourful beads in it. Every available cell denotes number of beads
        for a give move. Playing the game, beads are added and removed based on the game result in real time.
    </p>
    <div id="scroller">
        <div id="slide-container">
            <div id="brains"></div>
        </div>
    </div>
    <div class="holder"></div>

    <h2 id="reinforcement-learning">Reinforcement learning</h2>
    <p>
        Like in the MENACE case, the fundamental idea of <em>reinforcement learning</em> is to learn from experience with a
        <em>carrot and stick</em> method. Where moves which leads to a positive outcome are rewarded with a
        <em>carrot</em> and negative ones are punished with a <em>stick</em>.
    </p>
    <p>
        One of the MENACE problems was that it could <em>dies out of memory</em> or some matchboxes lost all beads and
        MENACE couldn't move forward <sup><a href="#dies-out-note">3)</a></sup>. Learning from MENACE <em>discrete</em>
        idea we can develop a continues realisation in <em>probability space</em> which will avoid a likely scenario
        of running out of actions.
    </p>
    <h3>Reward and value function</h3>
    <p>
        There are some moves which obviously lead to the end of the game and we can assign its final rewards. However,
        for majority of turns we don't know which tends to win the game and which to lose and draw. Because of that
        we will distinguish between <strong>reward</strong>, which gives immediate results and <strong>value
        function</strong> which measures the potential of future rewards.
    </p>
    <p>
        As we are playing, winning and losing, we would like to <em>back propagate</em> rewards from the last moves into
        the earlier stages of the game. If an agent win the game, we reward it with 1, on the other hand for lost
        and draw we assigns no point. To do so we define a <strong>value function</strong> V(&middot;) which assigns
        potential to every state of board S<sub>t</sub>. In each game we retrospectively update the values using
        this formula. [3]
    </p>
    <div class="center">
        V(S<sub>t</sub>) &leftarrow; V(S<sub>t</sub>) + &alpha; [V(S<sub>t+1</sub>) - V(S<sub>t</sub>)]
    </div>
    <p>
        The value is derived as a difference between value of previous step (or a reward for final steps) and value
        of the current step. It is discounted by a learning rate &alpha;. Initially, we assign 1s or 0s to all
        winning and losing states and 0.5 to all others <em>middle-states</em>.
    </p>

    <h3>Exploration vs exploitation</h3>
    <p>
        If we've played the game purely based on the value function, it is likely that we would stick to play the same
        all over again. Therefore, we will introduce concept of <em>exploration</em> vs <em>exploitation</em>. In
        exploration case we pick an action at random regardless on its value. On the other hand, for exploitation we
        pick the action with highest value. We can alternate those methods at random with &epsilon; probability,
        therefore, we tend to call this method an &epsilon;-greedy <em>policy</em>.
    </p>

    <h2>Conclusion</h2>
    <p>
        "<em>A reason for being interested in games is that they provide a microcosm of intellectual activity in general.
        Those thought processes which we regard as being specifically human accomplishments‚Äîlearning from experience,
        inductive reasoning, argument by analogy, the formation and testing of new hypotheses, and so on ‚Äî are brought
        into play even by simple games of mental skill.</em>", said Donald Michie [1]. I think games are specific
        area of intellectual stimulus which could be computationally solved, such as the example of tic-tac-toe.
        Therefore, it is worth exploring and playing with colourful approaches how we can reach <em>almost</em> unbeatable
        perfect player.
    </p>
    <p>
        Additionally, it is spectacular how a simple game, which <em>every seven years old children
        learns how to play and not to lose</em>, can attract so much of human interest and different branches of mathematics
        and computer science.
    </p>
    <p>
        You can find Python and JavaScript codes for each method in the
        <a href="https://github.com/matejker/tic-tac-toe">GitHub repo</a>.
    </p>

    <h2 class="reference">References:</h2>
    <ol class="reference">
        <li>
            Michie, D. (1963), <em>"Experiments on the mechanization of game-learning Part I. Characterization of the
            model
            and its parameters"</em>, <a href="https://people.csail.mit.edu/brooks/idocs/matchbox.pdf">Link</a>
        </li>
        <li>
            Michie, D. (1961) <em>"Trial and error"</em>. Penguin Science Survey.
        </li>
        <li>
            Sutton, R. S. & Barto, A. G. (2018), <em>"Reinforcement Learning: An Introduction"</em>, The MIT Press.
        </li>
        <li>
            Mitchell, M. (2019), <em>"Artificial intelligence a guide for thinking humans"</em>, Pelican books
        </li>
        <li>
            Scroggs, M. (2015), <em>"MENACE: Machine Educable Noughts And Crosses Engine"</em>,
            <a href="https://www.mscroggs.co.uk/blog/19">Blog post</a> &
            <a href="https://www.mscroggs.co.uk/menace/">Game</a>
        </li>
        <li>
            Luce, R. D. & Raiffa, H. (1957). <em>"Games and decisions: Introduction and critical survey"</em>.
            New York: Wiley.
        </li>
    </ol>

    <ol class="foot-notes">
        <li id="permutation-cycle-note">
            In cycle form we denote only permutations which maps themself in a consecutive <em>chain of elements</em>
            and leave all elements which maps on themself (fixed points).
        </li>
        <li id="counting-thm-note">
            We can re-frame the lemma to <em>number of possible colorings of a 3x3 grid by three colors</em>, we
            get:
            $$\frac{1}{|D_4|}\sum_{g\in G}\big |X^g \big| = \frac{1}{8}\bigg( 1\times 3^9 + 3 \times 3^1 + 4 \times 3^3
            \bigg)
            = 19\ 683$$
            (<em>There is one element which leaves all elements unchanged [identity], there are 3 [rotations] which
            leave
            one element unchanged and 4 [axes] which leave 3 elements unchanged.</em>) <br>
            Unfortunately, it says nothing about game <em>possibility</em> - if such board could exists (e.g. all fields
            are "X"), but it gives us better upper bound.
        </li>
        <li id="dies-out-note">
            Actually, there is 1:5 chance that MENACE dies out of beads. One of the possible solution is to add more
            beads initially; 8 for first turn, 4 for third, 2 for fifth and 1 for seventh.
        </li>
    </ol>
</div>
<footer>
    &copy; Matej Kerekrety 2021 <a href="https://github.com/matejker/tic-tac-toe"><img src="./img/github.png"></a>
</footer>

<script>
    const ctx = document.getElementById('myChart').getContext('2d');

    const data = {
      labels: xAxis,
      datasets: [
        {
          data: totalBeadsAdded,
          borderColor: 'rgba(0, 113, 133, 0.9)',
          fill: false,
          tension: 0.1
        }
      ]
    };

    const config = {
      type: 'line',
      data: data,
      options: {
        responsive: true,
        plugins: {
          title: {
            display: false
          },
          legend: {
            display: false,
          },
          tooltip: {
              enabled: false
          }
        },
        scales: {
          x: {
            display: true,
            title: {
              display: true,
               text: 'Number of games'
            }
          },
          y: {
            display: true,
            title: {
              display: true,
              text: 'Win: +' + rewards.won + '; lost: ' + rewards.lost + '; draw: +' + rewards.draw
            },
            ticks: {
              stepSize: 1
            }
          }
        }
      },
    };


    const cumulativeRewardMenace = new Chart(ctx, config);
</script>

</body>
</html>